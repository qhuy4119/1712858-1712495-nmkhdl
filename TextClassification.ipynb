{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xiuNKyNRvivx66mbTIY2tn-epz-c8_Yt",
      "authorship_tag": "ABX9TyM/CNHvNLF1YmgM8qb3ZmGk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qhuy4119/1712858-1712495-nmkhdl/blob/main/TextClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54ybb16j5V5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6be55b0-06d0-46f4-ddbd-177a34d628f6"
      },
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "!pip install fairseq\n",
        "!pip install fastBPE\n",
        "\n",
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.models.roberta import RobertaModel\n",
        "\n",
        "!wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n",
        "!tar -xzvf PhoBERT_base_fairseq.tar.gz\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.6/dist-packages (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.19.4)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.4.14)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.0.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.8)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (4.8)\n",
            "Requirement already satisfied: omegaconf<2.1,>=2.0.5 in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (2.0.5)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (3.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (3.7.4.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.6/dist-packages (from omegaconf<2.1,>=2.0.5->hydra-core->fairseq) (5.3.1)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq) (3.4.0)\n",
            "Requirement already satisfied: fastBPE in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "--2021-01-09 20:30:16--  https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n",
            "Resolving public.vinai.io (public.vinai.io)... 99.86.35.23, 99.86.35.72, 99.86.35.98, ...\n",
            "Connecting to public.vinai.io (public.vinai.io)|99.86.35.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1243308020 (1.2G) [application/x-tar]\n",
            "Saving to: ‘PhoBERT_base_fairseq.tar.gz.1’\n",
            "\n",
            "RT_base_fairseq.tar  31%[=====>              ] 371.08M  32.2MB/s    eta 29s    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiE58bg37Otq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "4dd79e4f-c149-406c-f524-592275acda34"
      },
      "source": [
        "data_path=r'/content/drive/MyDrive/Học tập/Introduce Data Science/Đố án/output.csv'\n",
        "\n",
        "df= pandas.read_csv(data_path)\n",
        "\n",
        "labels=set(df['forumName'])\n",
        "\n",
        "data=dict()\n",
        "\n",
        "for label in labels:\n",
        "  data[label]=[]\n",
        "\n",
        "for index,row in df.iterrows():\n",
        "  for label in labels:\n",
        "    if row['forumName']==label:\n",
        "      data[label].append(row['postCotent'])\n",
        "\n",
        "for label in labels:\n",
        "  print(label,': ',len(data[label]))\n",
        "\n",
        "def labelToNum(label):\n",
        "  for (index, value) in enumerate(labels):\n",
        "    if value==label:\n",
        "      return index;\n",
        "  return 0;\n",
        "\n",
        "def numToLabel(num):\n",
        "  for (index, value) in enumerate(labels):\n",
        "    if index==num:\n",
        "      return value;\n",
        "  return data[data.keys()[0]];\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Phim / Nhạc / Sách :  1463\n",
            "4 bánh :  1120\n",
            "Điện thoại di động :  1636\n",
            "Đồ điện tử & Thiết bị gia dụng :  1340\n",
            "Chuyện trò linh tinh™ :  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>postTitle</th>\n",
              "      <th>postCotent</th>\n",
              "      <th>forumName</th>\n",
              "      <th>postLink</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bán 8 Plus gold 64g còn bh ở didongviet 10 tháng</td>\n",
              "      <td>Máy ngoại hình tốt, ko sướt cấn móp. Pin 100%....</td>\n",
              "      <td>Điện thoại di động</td>\n",
              "      <td>https://voz.vn/t/ban-8-plus-gold-64g-con-bh-o-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mới sắm con máy giặt LG AI DD ưng quá lên khoe...</td>\n",
              "      <td>Hello mấy thím, nhân hôm không phải trông con ...</td>\n",
              "      <td>Đồ điện tử &amp; Thiết bị gia dụng</td>\n",
              "      <td>https://voz.vn/t/moi-sam-con-may-giat-lg-ai-dd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Những đồ thiết yếu cần lắp cho ô tô</td>\n",
              "      <td>Mời các bác vào tham luận cho vui. cái g...</td>\n",
              "      <td>4 bánh</td>\n",
              "      <td>https://voz.vn/t/nhung-do-thiet-yeu-can-lap-ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thái Mỹ Đình, Ép kính, Ép cáp, Thay Màn, Thay ...</td>\n",
              "      <td>Xin phép Add duyệt bài !!!\\nGiúp đỡ , tạo điều...</td>\n",
              "      <td>Điện thoại di động</td>\n",
              "      <td>https://voz.vn/t/thai-my-dinh-ep-kinh-ep-cap-t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Điện thoại Samsung S9+ hàng ssvn, full box, hì...</td>\n",
              "      <td>Mới nâng cấp máy, cần bán  hàng chính hãng SSV...</td>\n",
              "      <td>Điện thoại di động</td>\n",
              "      <td>https://voz.vn/t/dien-thoai-samsung-s9-hang-ss...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           postTitle  ...                                           postLink\n",
              "0   Bán 8 Plus gold 64g còn bh ở didongviet 10 tháng  ...  https://voz.vn/t/ban-8-plus-gold-64g-con-bh-o-...\n",
              "1  Mới sắm con máy giặt LG AI DD ưng quá lên khoe...  ...  https://voz.vn/t/moi-sam-con-may-giat-lg-ai-dd...\n",
              "2          Những đồ thiết yếu cần lắp cho ô tô  ...  https://voz.vn/t/nhung-do-thiet-yeu-can-lap-ch...\n",
              "3  Thái Mỹ Đình, Ép kính, Ép cáp, Thay Màn, Thay ...  ...  https://voz.vn/t/thai-my-dinh-ep-kinh-ep-cap-t...\n",
              "4  Điện thoại Samsung S9+ hàng ssvn, full box, hì...  ...  https://voz.vn/t/dien-thoai-samsung-s9-hang-ss...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDQ8YT4l9kFo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1e132cea-7c25-4e3e-80b2-6c1b3a4ce08d"
      },
      "source": [
        "# Data to plot\n",
        "labels=labels\n",
        "countings = []\n",
        "for label in labels:\n",
        "  countings.append(len(data[label]))\n",
        "\n",
        "# Plot\n",
        "plt.pie(countings, labels=labels,\n",
        "autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bZVCbEw94th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5452a88f-7fcd-4cba-9a54-13cf2230392a"
      },
      "source": [
        "phoBERT = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')\n",
        "class BPE():\n",
        "  bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
        "\n",
        "args = BPE()\n",
        "\n",
        "phoBERT.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT\n",
        "\n",
        "print(phoBERT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RobertaHubInterface(\n",
            "  (model): RobertaModel(\n",
            "    (encoder): RobertaEncoder(\n",
            "      (sentence_encoder): TransformerSentenceEncoder(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (embed_tokens): Embedding(64001, 768, padding_idx=1)\n",
            "        (embed_positions): LearnedPositionalEmbedding(258, 768, padding_idx=1)\n",
            "        (layers): ModuleList(\n",
            "          (0): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (1): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (2): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (3): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (4): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (5): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (6): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (7): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (8): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (9): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (10): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "          (11): TransformerSentenceEncoderLayer(\n",
            "            (dropout_module): FairseqDropout()\n",
            "            (activation_dropout_module): FairseqDropout()\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (dropout_module): FairseqDropout()\n",
            "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (lm_head): RobertaLMHead(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (classification_heads): ModuleDict()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwoS_QX0BQxN"
      },
      "source": [
        "MAX_LENGTH=255\n",
        "WORD_SIZE=768\n",
        "\n",
        "class GetData(Dataset):\n",
        "  def __init__(self,data,transform=None):\n",
        "    self.data= data\n",
        "    self.transform=transform\n",
        "    self.dataLoader=[]\n",
        "\n",
        "  def __len__(self):\n",
        "    sum=0\n",
        "    for key in data.keys():\n",
        "      sum=sum+len(self.data[key])\n",
        "    return sum\n",
        "\n",
        "  def getItemHelper(self,idx):\n",
        "    count=0;\n",
        "    x=\"\"\n",
        "    y=0\n",
        "    for key in self.data.keys():\n",
        "      for value in data[key]:\n",
        "        if(count==idx):\n",
        "\n",
        "          x=str(value).replace('\\n',' ');\n",
        "          y=labelToNum(key)\n",
        "          if len(x)>MAX_LENGTH:\n",
        "            x=x[:MAX_LENGTH]\n",
        " \n",
        "          try:\n",
        "            doc = phoBERT.extract_features_aligned_to_words(x)\n",
        "            return(doc,y)\n",
        "          except:\n",
        "            return self.getItemHelper(idx-1)\n",
        "        count=count+1\n",
        "    return (x,y)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    (x,y)=self.getItemHelper(index)\n",
        "    \n",
        "    rs=[]\n",
        "    for i in range(255):\n",
        "      try:\n",
        "        rs.append(x[i].vector.detach().numpy());\n",
        "        \n",
        "      except:\n",
        "        padding=np.zeros(WORD_SIZE)\n",
        "        rs.append(padding)\n",
        "\n",
        "    rs=np.array(rs);\n",
        "\n",
        "    y_label = y\n",
        "\n",
        "    if self.transform:\n",
        "      rs=self.transform(rs)\n",
        "\n",
        "    return (rs,y_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOzV4TECcmtE"
      },
      "source": [
        "train_size=4000\n",
        "test_size=1560\n",
        "\n",
        "transform=transforms.ToTensor()\n",
        "dataset= GetData(data,transform)\n",
        "DataLoader\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ET-78gDgkKU"
      },
      "source": [
        "batch_size=64\n",
        "\n",
        "train_loader= DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mtB2k_Jx_pn"
      },
      "source": [
        "input_size=768\n",
        "sequence_length=255\n",
        "num_layers=2\n",
        "hidden_size=256\n",
        "num_classes=len(data.keys())\n",
        "learning_rate=0.001\n",
        "num_epochs=2\n",
        "\n",
        "# Create RNN\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_layers,num_classes):\n",
        "    super(RNN,self).__init__()\n",
        "    self.hidden_size=hidden_size\n",
        "    self.num_layers=num_layers\n",
        "    self.rnn= nn.RNN(input_size,hidden_size,num_layers,batch_first=True)\n",
        "    self.fc=nn.Linear(hidden_size*sequence_length,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    h0=torch.zeros(self.num_layers,x.size(0),self.hidden_size).to(device)\n",
        "    \n",
        "    out,_=self.rnn(x,h0)\n",
        "    out=out.reshape(out.shape[0],-1);\n",
        "    out=self.fc(out)\n",
        "\n",
        "    return out;\n",
        "\n",
        "model = RNN(input_size,hidden_size,num_layers,num_classes);\n",
        "\n",
        "model(dataset.__getitem__(0)[0].float())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Mk9CsZgnST"
      },
      "source": [
        "model= RNN(input_size,hidden_size,num_layers,num_classes).to(device)\n",
        "criterion= nn.CrossEntropyLoss();\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwKXU2ECgrnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ebd635d-13d4-4add-8b1f-fa7dde26ba8b"
      },
      "source": [
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(data_train,targets) in enumerate(train_loader):\n",
        "    # Get data to Cuda if possible\n",
        "    #data=data.to(device=device).squeeze(1);\n",
        "    data_train=data_train.to(device=device).squeeze(1);\n",
        "    targets=targets.to(device=device);\n",
        "    \n",
        "    # Get data ro correct shape\n",
        "    #data=data.reshape(data.shape[0],-1)\n",
        "    #data=data.reshape(batch_size,sequence_length,input_size)\n",
        "\n",
        "\n",
        "    # Forward\n",
        "    scores=model(data_train.float());\n",
        "    loss= criterion(scores,targets);\n",
        "\n",
        "    print(loss)\n",
        "\n",
        "    # Backward\n",
        "    optimizer.zero_grad();\n",
        "    loss.backward();\n",
        "\n",
        "    # Gradient Descent\n",
        "    optimizer.step();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.6332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.6332, grad_fn=<NllLossBackward>)\n",
            "tensor(3.7145, grad_fn=<NllLossBackward>)\n",
            "tensor(3.7145, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9373, grad_fn=<NllLossBackward>)\n",
            "tensor(1.9373, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3530, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3530, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0491, grad_fn=<NllLossBackward>)\n",
            "tensor(2.0491, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3643, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3643, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4169, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4169, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4461, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4461, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0679, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0679, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0332, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7917, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7917, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7863, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7863, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8818, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8818, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7428, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7428, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9002, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9002, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0315, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0315, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5004, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6864, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6864, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5613, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4826, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4826, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6111, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6111, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6278, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6278, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4041, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4923, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4923, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4269, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4269, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5755, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5755, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5264, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5264, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6067, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6067, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5165, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5165, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3408, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3408, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6827, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6827, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5052, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5052, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6594, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6594, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4838, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4838, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5852, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5852, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3646, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3646, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5296, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5296, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7524, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7524, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7742, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7742, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4969, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4969, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6044, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6044, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4738, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4738, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2696, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2696, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4570, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4570, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3983, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3983, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3316, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3316, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2523, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2523, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4047, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4047, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5561, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5561, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4336, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4336, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3343, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3343, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3345, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3345, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2762, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2762, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4654, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4654, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4065, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4065, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4957, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4957, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3963, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3963, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5462, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5462, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5543, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5543, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2724, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2717, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2717, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1999, grad_fn=<NllLossBackward>)\n",
            "tensor(0.1999, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4409, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4409, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2979, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3711, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3711, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4741, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4741, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3955, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3955, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3935, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3935, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3167, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3167, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4263, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4263, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2747, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2747, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5368, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5368, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3810, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3810, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4059, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4059, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2127, grad_fn=<NllLossBackward>)\n",
            "tensor(0.2127, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkhYgCtYgwct"
      },
      "source": [
        "# Check accuracy on training & test to see how good our model\n",
        "\n",
        "def check_accuracy(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print(\"Checking accuracy on training data\")\n",
        "    else:\n",
        "        print(\"Checking accuracy on valid data\")\n",
        "\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    # Set model to eval\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device).squeeze(1)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(\n",
        "            f\"Got {num_correct} / {num_samples} with \\\n",
        "              accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
        "        )\n",
        "    # Set model back to train\n",
        "    model.train()\n",
        "\n",
        "    \n",
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader,model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}